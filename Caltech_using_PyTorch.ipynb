{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Caltech-using-PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "p_nmpCyUefno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "  \n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGaQy-7vexdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
        "!tar -xvzf 101_ObjectCategories.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QiOU8irOe3P2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"101_ObjectCategories/train\")\n",
        "os.makedirs(\"101_ObjectCategories/valid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQBw6iM05zwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_immediate_subdirectories(data_directory):\n",
        "    return [name for name in os.listdir(data_directory)\n",
        "            if os.path.isdir(os.path.join(data_directory, name))]\n",
        "\n",
        "def move_images(directory, train_dir, valid_dir, image_list, label):\n",
        "  # shuffle all images\n",
        "  random_set = np.random.permutation(len(image_list))\n",
        "  \n",
        "  # select 80% of images at random for train\n",
        "  train_list = random_set[:round(len(random_set) * 0.8)]\n",
        "  \n",
        "  # select 20% of images at randomf or valid\n",
        "  valid_list = random_set[-(len(image_list) - len(train_list))::]\n",
        "  \n",
        "  train_images = []\n",
        "  valid_images = []\n",
        "  \n",
        "  for index in train_list:\n",
        "    train_images.append(image_list[index])\n",
        "  \n",
        "  for index in valid_list:\n",
        "    valid_images.append(image_list[index])\n",
        "  \n",
        "  for train_image in train_images:\n",
        "    os.rename(os.path.join(directory, label, train_image), os.path.join(train_dir, label, train_image))\n",
        "  for valid_image in valid_images:\n",
        "    os.rename(os.path.join(directory, label, valid_image), os.path.join(valid_dir, label, valid_image))\n",
        "  \n",
        "  shutil.rmtree(os.path.join(directory, label))\n",
        "    \n",
        "#   os.removedirs(os.path.join(directory, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QALMgnb152Fg",
        "colab_type": "code",
        "outputId": "607e2e1d-986e-40e4-a432-20dc578a8c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3643
        }
      },
      "cell_type": "code",
      "source": [
        "# !rm -r 101_ObjectCategories/\n",
        "# !tar -xvzf 101_ObjectCategories.tar.gz\n",
        "# reference: https://gist.github.com/GertjanBrouwer/95c815565d3d8788137929ef27054db9\n",
        "\n",
        "train_dir = \"101_ObjectCategories/train/\"\n",
        "valid_dir = \"101_ObjectCategories/valid/\"\n",
        "\n",
        "dir_list = get_immediate_subdirectories(\"101_ObjectCategories/\")\n",
        "directory = \"101_ObjectCategories/\"\n",
        "\n",
        "# os.mkdir(train_dir)\n",
        "# os.mkdir(valid_dir)\n",
        "\n",
        "for dir_ in dir_list:\n",
        "  if dir_ == \"train\" or dir_ == \"valid\":\n",
        "    continue\n",
        "    \n",
        "  label = dir_\n",
        "  \n",
        "  print('Started moving: ' + str(label))\n",
        "  \n",
        "  image_list = [os.path.basename(x) for x in glob.glob(os.path.join(directory, label) + '/*.jpg')]\n",
        "  \n",
        "  if not os.path.exists(os.path.join(train_dir, label)):\n",
        "    os.mkdir(os.path.join(train_dir, label))\n",
        "  \n",
        "  if not os.path.exists(os.path.join(valid_dir, label)):\n",
        "    os.mkdir(os.path.join(valid_dir, label))\n",
        "  \n",
        "  directory = \"101_ObjectCategories/\"\n",
        "  \n",
        "  move_images(directory, train_dir, valid_dir, image_list, label)\n",
        "  \n",
        "  print(\"Finished moving: \" + str(label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started moving: elephant\n",
            "Finished moving: elephant\n",
            "Started moving: watch\n",
            "Finished moving: watch\n",
            "Started moving: euphonium\n",
            "Finished moving: euphonium\n",
            "Started moving: bonsai\n",
            "Finished moving: bonsai\n",
            "Started moving: flamingo\n",
            "Finished moving: flamingo\n",
            "Started moving: crocodile_head\n",
            "Finished moving: crocodile_head\n",
            "Started moving: sea_horse\n",
            "Finished moving: sea_horse\n",
            "Started moving: crayfish\n",
            "Finished moving: crayfish\n",
            "Started moving: chandelier\n",
            "Finished moving: chandelier\n",
            "Started moving: panda\n",
            "Finished moving: panda\n",
            "Started moving: ceiling_fan\n",
            "Finished moving: ceiling_fan\n",
            "Started moving: schooner\n",
            "Finished moving: schooner\n",
            "Started moving: headphone\n",
            "Finished moving: headphone\n",
            "Started moving: pyramid\n",
            "Finished moving: pyramid\n",
            "Started moving: minaret\n",
            "Finished moving: minaret\n",
            "Started moving: platypus\n",
            "Finished moving: platypus\n",
            "Started moving: dalmatian\n",
            "Finished moving: dalmatian\n",
            "Started moving: strawberry\n",
            "Finished moving: strawberry\n",
            "Started moving: cellphone\n",
            "Finished moving: cellphone\n",
            "Started moving: buddha\n",
            "Finished moving: buddha\n",
            "Started moving: butterfly\n",
            "Finished moving: butterfly\n",
            "Started moving: ibis\n",
            "Finished moving: ibis\n",
            "Started moving: gramophone\n",
            "Finished moving: gramophone\n",
            "Started moving: brain\n",
            "Finished moving: brain\n",
            "Started moving: pigeon\n",
            "Finished moving: pigeon\n",
            "Started moving: rhino\n",
            "Finished moving: rhino\n",
            "Started moving: crocodile\n",
            "Finished moving: crocodile\n",
            "Started moving: chair\n",
            "Finished moving: chair\n",
            "Started moving: ewer\n",
            "Finished moving: ewer\n",
            "Started moving: dolphin\n",
            "Finished moving: dolphin\n",
            "Started moving: stop_sign\n",
            "Finished moving: stop_sign\n",
            "Started moving: Leopards\n",
            "Finished moving: Leopards\n",
            "Started moving: hawksbill\n",
            "Finished moving: hawksbill\n",
            "Started moving: tick\n",
            "Finished moving: tick\n",
            "Started moving: ketch\n",
            "Finished moving: ketch\n",
            "Started moving: llama\n",
            "Finished moving: llama\n",
            "Started moving: bass\n",
            "Finished moving: bass\n",
            "Started moving: menorah\n",
            "Finished moving: menorah\n",
            "Started moving: umbrella\n",
            "Finished moving: umbrella\n",
            "Started moving: rooster\n",
            "Finished moving: rooster\n",
            "Started moving: beaver\n",
            "Finished moving: beaver\n",
            "Started moving: joshua_tree\n",
            "Finished moving: joshua_tree\n",
            "Started moving: pagoda\n",
            "Finished moving: pagoda\n",
            "Started moving: barrel\n",
            "Finished moving: barrel\n",
            "Started moving: inline_skate\n",
            "Finished moving: inline_skate\n",
            "Started moving: cougar_body\n",
            "Finished moving: cougar_body\n",
            "Started moving: soccer_ball\n",
            "Finished moving: soccer_ball\n",
            "Started moving: lotus\n",
            "Finished moving: lotus\n",
            "Started moving: garfield\n",
            "Finished moving: garfield\n",
            "Started moving: cannon\n",
            "Finished moving: cannon\n",
            "Started moving: wild_cat\n",
            "Finished moving: wild_cat\n",
            "Started moving: scissors\n",
            "Finished moving: scissors\n",
            "Started moving: windsor_chair\n",
            "Finished moving: windsor_chair\n",
            "Started moving: wheelchair\n",
            "Finished moving: wheelchair\n",
            "Started moving: flamingo_head\n",
            "Finished moving: flamingo_head\n",
            "Started moving: ferry\n",
            "Finished moving: ferry\n",
            "Started moving: revolver\n",
            "Finished moving: revolver\n",
            "Started moving: airplanes\n",
            "Finished moving: airplanes\n",
            "Started moving: water_lilly\n",
            "Finished moving: water_lilly\n",
            "Started moving: okapi\n",
            "Finished moving: okapi\n",
            "Started moving: wrench\n",
            "Finished moving: wrench\n",
            "Started moving: anchor\n",
            "Finished moving: anchor\n",
            "Started moving: pizza\n",
            "Finished moving: pizza\n",
            "Started moving: lamp\n",
            "Finished moving: lamp\n",
            "Started moving: sunflower\n",
            "Finished moving: sunflower\n",
            "Started moving: Motorbikes\n",
            "Finished moving: Motorbikes\n",
            "Started moving: binocular\n",
            "Finished moving: binocular\n",
            "Started moving: ant\n",
            "Finished moving: ant\n",
            "Started moving: scorpion\n",
            "Finished moving: scorpion\n",
            "Started moving: brontosaurus\n",
            "Finished moving: brontosaurus\n",
            "Started moving: helicopter\n",
            "Finished moving: helicopter\n",
            "Started moving: dragonfly\n",
            "Finished moving: dragonfly\n",
            "Started moving: metronome\n",
            "Finished moving: metronome\n",
            "Started moving: dollar_bill\n",
            "Finished moving: dollar_bill\n",
            "Started moving: laptop\n",
            "Finished moving: laptop\n",
            "Started moving: hedgehog\n",
            "Finished moving: hedgehog\n",
            "Started moving: stegosaurus\n",
            "Finished moving: stegosaurus\n",
            "Started moving: octopus\n",
            "Finished moving: octopus\n",
            "Started moving: BACKGROUND_Google\n",
            "Finished moving: BACKGROUND_Google\n",
            "Started moving: mandolin\n",
            "Finished moving: mandolin\n",
            "Started moving: accordion\n",
            "Finished moving: accordion\n",
            "Started moving: cup\n",
            "Finished moving: cup\n",
            "Started moving: nautilus\n",
            "Finished moving: nautilus\n",
            "Started moving: gerenuk\n",
            "Finished moving: gerenuk\n",
            "Started moving: crab\n",
            "Finished moving: crab\n",
            "Started moving: starfish\n",
            "Finished moving: starfish\n",
            "Started moving: Faces\n",
            "Finished moving: Faces\n",
            "Started moving: saxophone\n",
            "Finished moving: saxophone\n",
            "Started moving: camera\n",
            "Finished moving: camera\n",
            "Started moving: mayfly\n",
            "Finished moving: mayfly\n",
            "Started moving: yin_yang\n",
            "Finished moving: yin_yang\n",
            "Started moving: trilobite\n",
            "Finished moving: trilobite\n",
            "Started moving: snoopy\n",
            "Finished moving: snoopy\n",
            "Started moving: kangaroo\n",
            "Finished moving: kangaroo\n",
            "Started moving: electric_guitar\n",
            "Finished moving: electric_guitar\n",
            "Started moving: cougar_face\n",
            "Finished moving: cougar_face\n",
            "Started moving: car_side\n",
            "Finished moving: car_side\n",
            "Started moving: lobster\n",
            "Finished moving: lobster\n",
            "Started moving: stapler\n",
            "Finished moving: stapler\n",
            "Started moving: emu\n",
            "Finished moving: emu\n",
            "Started moving: grand_piano\n",
            "Finished moving: grand_piano\n",
            "Started moving: Faces_easy\n",
            "Finished moving: Faces_easy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VOvvkDkx59ST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Image transformations\n",
        "image_transforms = {\n",
        "    # Train uses data augmentation\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),  # Image net standards\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "    ]),\n",
        "    # Validation does not use augmentation\n",
        "    'valid':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Av5CaxaP6FV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "traindir = '101_ObjectCategories/train'\n",
        "validdir = '101_ObjectCategories/valid'\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Datasets from folders\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
        "    'valid':\n",
        "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid']),\n",
        "}\n",
        "\n",
        "# Dataloader iterators, make sure to shuffle\n",
        "dataloaders = {\n",
        "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
        "    'val': DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zm5VL6h46T82",
        "colab_type": "code",
        "outputId": "7298c684-b2a5-4444-d79d-351eb53b7b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "trainiter = iter(dataloaders['train'])\n",
        "features, labels = next(trainiter)\n",
        "features.shape, labels.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3, 224, 224]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "SrJpI7tO6bKZ",
        "colab_type": "code",
        "outputId": "4e8454a2-6857-4803-db28-4479d06aaf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "102502400it [00:02, 46613726.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ixt1pIgu62ry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Freeze model weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gpyIUIJ7MBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_file_name = 'resnet50-transfer-4.pt'\n",
        "checkpoint_path = 'resnet50-transfer-4.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q65g_XrB646-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "n_inputs = model.fc.in_features\n",
        "\n",
        "# Source: Abhijeet Patil, IIT B\n",
        "# model.fc = nn.Linear(n_inputs, 102)\n",
        "\n",
        "# Add on classifier\n",
        "model.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, 100),                   \n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eybb9rHJ8TfT",
        "colab_type": "code",
        "outputId": "db0e3b9c-3ab7-4f1f-f00f-5086d769d197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Find total parameters and trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24,058,276 total parameters.\n",
            "550,244 training parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4DDXWBi667Oq",
        "colab_type": "code",
        "outputId": "113dba0d-9a8e-493f-82b0-24eb45c9733f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "t = torch.Tensor([1, 2, 3])\n",
        "t.to(device)\n",
        "\n",
        "# model = model.to('cuda')\n",
        "# Distribute across 2 gpus\n",
        "# model = nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-f9a5d97f64a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = model.to('cuda')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Aetig_JI8dMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from torch import optim\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Source: Abhijeet Patil, IIT B\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9) \n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4xFg9TF8gGv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name,\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=20,\n",
        "          print_every=2):\n",
        "    \"\"\"Train a PyTorch Model\n",
        "\n",
        "    Params\n",
        "    --------\n",
        "        model (PyTorch model): cnn to train\n",
        "        criterion (PyTorch loss): objective to minimize\n",
        "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
        "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
        "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
        "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
        "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
        "        n_epochs (int): maximum number of training epochs\n",
        "        print_every (int): frequency of epochs to print training stats\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "        model (PyTorch model): trained cnn with best weights\n",
        "        history (DataFrame): history of train and validation loss and accuracy\n",
        "    \"\"\"\n",
        "    train_on_gpu = True\n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "\n",
        "    overall_start = time.time()\n",
        "\n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        start = time.time()\n",
        "\n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            if train_on_gpu:\n",
        "                print(data)\n",
        "#                 data, target = data.cuda(), target.cuda()\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predicted outputs are log probabilities\n",
        "            output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max log probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "\n",
        "            # Don't need to keep track of gradients\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Tensors to gpu\n",
        "                    if train_on_gpu:\n",
        "                        print(data)\n",
        "#                         data, target = data.cuda(), target.cuda()\n",
        "                        data = data.to(device)\n",
        "                        target = target.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    output = model(data)\n",
        "\n",
        "                    # Validation loss\n",
        "                    loss = criterion(output, target)\n",
        "                    # Multiply average loss times the number of examples in batch\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                    # Calculate validation accuracy\n",
        "                    _, pred = torch.max(output, dim=1)\n",
        "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                    accuracy = torch.mean(\n",
        "                        correct_tensor.type(torch.FloatTensor))\n",
        "                    # Multiply average accuracy times the number of examples\n",
        "                    valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                # Calculate average accuracy\n",
        "                train_acc = train_acc / len(train_loader.dataset)\n",
        "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "\n",
        "                # Print training and validation results\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(\n",
        "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                    )\n",
        "                    print(\n",
        "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                    )\n",
        "\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_file_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    valid_best_acc = valid_acc\n",
        "                    best_epoch = epoch\n",
        "\n",
        "                # Otherwise increment count of epochs with no improvement\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    # Trigger early stopping\n",
        "                    if epochs_no_improve >= max_epochs_stop:\n",
        "                        print(\n",
        "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "                        )\n",
        "                        total_time = time.time() - overall_start\n",
        "                        print(\n",
        "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                        )\n",
        "\n",
        "                        # Load the best state dict\n",
        "                        model.load_state_dict(torch.load(save_file_name))\n",
        "                        # Attach the optimizer\n",
        "                        model.optimizer = optimizer\n",
        "\n",
        "                        # Format history\n",
        "                        history = pd.DataFrame(\n",
        "                            history,\n",
        "                            columns=[\n",
        "                                'train_loss', 'valid_loss', 'train_acc',\n",
        "                                'valid_acc'\n",
        "                            ])\n",
        "                        return model, history\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = time.time() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # Format history\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGmIbs5v8qoh",
        "colab_type": "code",
        "outputId": "e25609d2-4846-4a6a-e160-51c69fce732e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3067
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "model, history = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training from Scratch.\n",
            "\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4508,  0.4337,  0.4679,  ...,  0.7762,  0.8104,  0.7762],\n",
            "          [ 0.5364,  0.4508,  0.4337,  ...,  0.7933,  0.8104,  0.7933],\n",
            "          [ 0.3823,  0.2453,  0.3823,  ...,  0.8447,  0.8789,  0.8104],\n",
            "          ...,\n",
            "          [ 1.5810,  1.5810,  1.5982,  ..., -1.7583, -1.9295, -1.9295],\n",
            "          [ 1.5468,  1.5810,  1.6153,  ..., -1.6898, -1.8268, -1.8782],\n",
            "          [ 1.5810,  1.5810,  1.5810,  ..., -1.5528, -1.6727, -1.6555]],\n",
            "\n",
            "         [[-0.5126, -0.5301, -0.4776,  ...,  0.1527,  0.2052,  0.2227],\n",
            "          [-0.4251, -0.5126, -0.5126,  ...,  0.1702,  0.2052,  0.2402],\n",
            "          [-0.5651, -0.7227, -0.5651,  ...,  0.2227,  0.2577,  0.2577],\n",
            "          ...,\n",
            "          [ 1.7808,  1.7808,  1.7983,  ..., -0.8803, -1.1253, -1.1779],\n",
            "          [ 1.7458,  1.7808,  1.8158,  ..., -0.8102, -1.0028, -1.1078],\n",
            "          [ 1.7808,  1.7808,  1.7808,  ..., -0.6702, -0.8452, -0.8803]],\n",
            "\n",
            "         [[-0.8981, -0.9156, -0.8981,  ..., -0.2184, -0.1835, -0.1661],\n",
            "          [-0.8110, -0.9156, -0.9330,  ..., -0.2184, -0.1835, -0.1138],\n",
            "          [-0.9678, -1.1247, -1.0201,  ..., -0.1661, -0.1312, -0.0615],\n",
            "          ...,\n",
            "          [ 1.9777,  1.9777,  1.9951,  ..., -0.6018, -0.8981, -0.9504],\n",
            "          [ 1.9428,  1.9777,  2.0125,  ..., -0.5321, -0.7761, -0.8981],\n",
            "          [ 1.9777,  1.9777,  1.9777,  ..., -0.4101, -0.6367, -0.6715]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.1975,  2.1804,  2.1804],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.1804,  2.2147,  2.2147],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.0948,  2.1804,  2.2318],\n",
            "          ...,\n",
            "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 2.2489,  2.2489,  2.2489,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  2.3761,  2.3585,  2.3585],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3585,  2.3936,  2.3936],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.2710,  2.3585,  2.4111],\n",
            "          ...,\n",
            "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  2.5877,  2.5703,  2.5703],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.5703,  2.6051,  2.6051],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.4831,  2.5703,  2.6226],\n",
            "          ...,\n",
            "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-487a560aa2cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmax_epochs_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     print_every=2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-911daf0a236f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, save_file_name, max_epochs_stop, n_epochs, print_every)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#                 data, target = data.cuda(), target.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vddq2O7nsksE",
        "colab_type": "code",
        "outputId": "61f2a891-06d7-4de4-8af7-297b313be85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "fln_oHEFBq6g",
        "colab_type": "code",
        "outputId": "100b6ce9-71da-4e97-b0a8-33fd626d78d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "model, history = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has been trained for: 0 epochs.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1f2a803ba7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_epochs_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     print_every=2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-ed635c7e02e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, save_file_name, max_epochs_stop, n_epochs, print_every)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Tensors to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XHBBpspUvWD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}